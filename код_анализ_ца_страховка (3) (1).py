# -*- coding: utf-8 -*-
"""Код_Анализ_ЦА_страховка.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SVqNxMmtb6akJM5czPUJrUb19WVUpRGR
"""



def preprocess_text(text):
    # Лемматизируем токены, приводим их к нижнему регистру
    tokens = mystem.lemmatize(text.lower())
    # Пропускаем токен, если он пустой или находится в списке стоп-слов
    clean_tokens = []
    for token in tokens:
        if token not in russian_stopwords and token != " " and token.strip() not in punctuation:
            clean_tokens.append(token)
    # Объединяем токены назад в текст
    text = " ".join(clean_tokens)
    return text

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
import statsmodels.api as sm
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
import nltk
nltk.download("stopwords")
from nltk.corpus import stopwords
from pymystem3 import Mystem
from string import punctuation
from collections import Counter
import matplotlib.pyplot as plt
from nltk.tokenize import word_tokenize, sent_tokenize
import nltk
nltk.download('punkt')
!pip install rutermextract
from rutermextract import TermExtractor
!pip install git+http://github.com/LIAAD/yake
import yake



data = pd.read_csv('Опрос-ЦА.csv')
data.head()

data.info()

#изменение названия столбцов
data = data.rename(columns = {'3. Где предпочитаете путешествовать: в пределах России или за границей?  (Если ответили "да" на предыдущий вопрос)' : "Направления",
                             '4. Приобретаете страховку при путешествиях?  (Если ответили "да" на 2 вопрос)':'Страховка при путешествии',
                             '5. Что вас заставило задуматься о приобретении страховки? (Если ответили "да" на 4 вопрос)':'Зачем берут',
                             '6. Почему не приобретаете страховку при путешествиях? (Если ответили "нет" на 4 вопрос)':'Почему не берут',
                             '7. Что сподвигнуло бы вас на приобретение страхования во время путешествий? (Если ответили "нет" на 4 вопрос)':'Что сподвигнуло б взять',
                             '8. Если вы оформляли страховку у Сбер Страхования, какие были неудобства во время процесса ее оформления? Есть ли у вас пожелания к улучшению данного процесса?   (Если ответили "да" на 4 вопрос)':'Неудобства сбер'
                             }
                   )
data.info()

#Отбор признаков для графиков
data_grafic = data.drop(['Отметка времени',
                         'Зачем берут',
                         'Почему не берут',
                         'Что сподвигнуло б взять',
                         'Неудобства сбер'
                         ],
                          axis = 1)
#Замена пустых ячеек
data_grafic['Направления'] = data_grafic['Направления'].fillna('Не путешествую')
data_grafic['Страховка при путешествии'] = data_grafic['Страховка при путешествии'].fillna(0)

#Обработка данных для регрессии
data_reg = data.drop(data.columns[0], axis=1)
replace_dict = {'Да': 1, 'Нет': 0}
data_reg['1. Вы работаете?'] = data_reg['1. Вы работаете?'].replace(replace_dict)
data_reg['2. Вы путешествуете?'] = data_reg['2. Вы путешествуете?'].replace(replace_dict)
data_reg['Страховка при путешествии'] = data_reg['Страховка при путешествии'].replace(replace_dict)
data_reg['Страховка при путешествии'].fillna(0, inplace=True)
data.info()

#Визуализация
plt.subplot(2, 1, 1)
plt.hist(data_grafic['1. Вы работаете?'], color = 'violet', bins = 3)
plt.xticks(rotation=45)
plt.title('Ответы на вопрос "Работате ли вы?"')
plt.ylabel("Количество человек")

plt.subplot(2, 1, 2)
plt.hist(data_grafic['2. Вы путешествуете?'], color = 'red', bins = 3)
plt.xticks(rotation=45)
plt.title('Ответы на вопрос "Путешествуете ли вы?"')
plt.ylabel("Количество человек")

# Убираем строки, так чтобы остались лишь те где значение столбца о приобритении страховки не пустое и человек путешествует
df = data_grafic.loc[data_grafic['Страховка при путешествии'] != 0]
df = df.loc[data_grafic['2. Вы путешествуете?'] != "Нет"]

#Визуализация направлений путешественников
sns.barplot(data=df['Направления'].value_counts(), orient="h")

#Визуализация ответов на вопрос о офрмлении страховки
plt.hist(df['Страховка при путешествии'], color = 'green', bins = 3)
plt.xticks(rotation=45)
plt.title('Ответы на вопрос "Берете ли страховку ?"')
plt.ylabel("Количество человек")

#Сравнение  между путешесвующими и работающими
plt.subplots(figsize=(8, 8))
srav_gist = pd.DataFrame({
    x_label: grp['2. Вы путешествуете?'].value_counts()
    for x_label, grp in data.groupby('1. Вы работаете?')
})
sns.heatmap(srav_gist, cmap='viridis')
plt.xlabel('1. Вы работаете?')
plt.ylabel('2. Вы путешествуете?')

#Сравнение  между направлениями и приобритением страховки
plt.subplots(figsize=(8, 8))
df_2dhist = pd.DataFrame({
    x_label: grp['Страховка при путешествии'].value_counts()
    for x_label, grp in data.groupby('Направления')
})
sns.heatmap(df_2dhist, cmap='viridis')
plt.xlabel('Направления')
plt.ylabel('Страховка при путешествии')

"""Регрессия (как зависит наличие страховки от наличия работы и путешествий)"""

# Преобразуем столбец в целочисленный тип данных
data_reg['Страховка при путешествии'] = data_reg['Страховка при путешествии'].astype(int)
# Выбираем столбцы для модели
selected_columns = ['1. Вы работаете?', '2. Вы путешествуете?', 'Страховка при путешествии']
data_for_regression = data_reg[selected_columns]

# Разделяем данные на признаки (X) и целевую переменную (y)
features = data_for_regression[['2. Вы путешествуете?', '1. Вы работаете?']]
target = data_for_regression['Страховка при путешествии']

# Разделяем данные на обучающий и тестовый наборы
features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.25, random_state=42)

# Создаем модель линейной регрессии
model = LinearRegression()

# Обучаем модель на обучающем наборе
model.fit(features_train, target_train)

# Делаем прогноз на тестовом наборе
result = model.predict(features_test)
result

# Извлекаем коэффициенты и свободный член
coefficients = model.coef_  # Массив коэффициентов для каждого признака
intercept = model.intercept_

# Выводим уравнение линейной регрессии
equation = f"y = {intercept}"
for i, coef in enumerate(coefficients):
    equation += f" + ({coef} * X{i+1})"
print("Уравнение линейной регрессии:", equation)

#p-value
# Добавим постоянное значение к входным данным (требуется statsmodels)
features_train = sm.add_constant(features_train)

# Обучаем ту же модель, только в помощью другой библиотеки
model = sm.OLS(target_train, features_train).fit()

# Получаем p-values для каждого признака
p_values = model.pvalues

# Находим p-values
print("P-value для каждого параметра:")
for i, p_value in enumerate(p_values[1:]):
    print(f"Признак {i+1}: {p_value}")

# Оцениваем качество модели с помощью средней квадратичной ошибки
mse = mean_squared_error(target_test, result)
print("Mean Squared Error: ", mse)

# Оцениваем качество глупой модели
target_train.mean()

# создадим список с одинаковыми значениями (средними), размером с тестовую выборку (чтобы правильно рассчитать MSE):
dumb_model_result = [target_train.mean()]*len (target_test)

# Вычисляем MSE “глупой” модели
mean_squared_error(target_test, dumb_model_result)

# R2
r2_score(target_test, result)

"""Лингвистический анализ ответов"""



mystem = Mystem()
russian_stopwords = stopwords.words("russian")
stop =['хз', ' -- ', 'мочь']
russian_stopwords.extend(stop)

#Удаление пустыхзначений в 5 столбце
df_lin_5 = data.copy()
df_lin_5['Зачем берут'] = df_lin_5['Зачем берут'].fillna(0)
df_lin_5 = df_lin_5.loc[df_lin_5['Зачем берут'] != 0]
df_lin_5.head()

#Удаление пустыхзначений в 7 столбце
df_lin_7 = data.copy()
df_lin_7['Что сподвигнуло б взять'] = df_lin_7['Что сподвигнуло б взять'].fillna(0)
df_lin_7 = df_lin_7.loc[df_lin_7['Что сподвигнуло б взять'] != 0]
df_lin_7.head()

"""Анализ вопроса для чего берут страховку во время путешествий"""

toc = ''
#По очереди добавляем к ней каждый элемент списка
for el in df_lin_5['Зачем берут']:
    toc += str(el)+ " "
print(toc)

preprocess_text(toc)

# Устанавливаем библиотеку RuTermExtract и необходимые модули
term_extractor = TermExtractor()

# Выводим поочередно ключевое слово и количество его вхождений в текст
for term in term_extractor(toc):
    print(term.normalized, term.count)

# Алгоритм YAKE
kw_extractor = yake.KeywordExtractor()
keywords = kw_extractor.extract_keywords(toc)

# Выводим извлеченные ключевые слова и вероятность, отражающую степень важности ключевого слова
for kw in keywords:
    print(kw[0])



"""Анализ вопроса "Что сподвигнуло бы вас на получение страховки?"
"""

roc = ''
#По очереди добавляем к ней каждый элемент списка
for el in df_lin_7['Что сподвигнуло б взять']:
    roc += str(el)+ " "
print(roc)

preprocess_text(roc)

# Устанавливаем библиотеку RuTermExtract и необходимые модули
term_extractor = TermExtractor()

# Выводим поочередно ключевое слово и количество его вхождений в текст
for term in term_extractor(roc):
    print(term.normalized, term.count)

# Алгоритм YAKE
kw_extractor = yake.KeywordExtractor()
keywords = kw_extractor.extract_keywords(roc)

# Выводим извлеченные ключевые слова и вероятность, отражающую степень важности ключевого слова
for kw in keywords:
    print(kw[0])